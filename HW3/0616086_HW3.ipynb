{"cells":[{"cell_type":"markdown","metadata":{"id":"FPISQk91lPvA"},"source":["## HW3: Decision Tree, AdaBoost and Random Forest\n","In hw3, you need to implement decision tree, adaboost and random forest by using only numpy, then train your implemented model by the provided dataset and test the performance with testing data\n","\n","Please note that only **NUMPY** can be used to implement your model, you will get no points by simply calling sklearn.tree.DecisionTreeClassifier"]},{"cell_type":"code","source":["!pip install pycodestyle\n","!pip install --index-url https://test.pypi.org/simple/ nbpep8"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BsVPdJxHzImh","executionInfo":{"status":"ok","timestamp":1651933889074,"user_tz":-480,"elapsed":6494,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"b706d11f-4885-4190-e624-fa080e17c1f7"},"execution_count":415,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pycodestyle in /usr/local/lib/python3.7/dist-packages (2.8.0)\n","Looking in indexes: https://test.pypi.org/simple/\n","Requirement already satisfied: nbpep8 in /usr/local/lib/python3.7/dist-packages (0.0.15)\n"]}]},{"cell_type":"markdown","metadata":{"id":"kisBijfAlPvD"},"source":["## Load data\n","The dataset is the Heart Disease Data Set from UCI Machine Learning Repository. It is a binary classifiation dataset, the label is stored in `target` column. **Please note that there exist categorical features which need to be [one-hot encoding](https://www.datacamp.com/community/tutorials/categorical-data) before fit into your model!**\n","See follow links for more information\n","https://archive.ics.uci.edu/ml/datasets/heart+Disease"]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","from nbpep8.nbpep8 import pep8\n","from google.colab import drive\n","import pandas as pd\n","import numpy as np\n","drive.mount('/content/drive')\n","\n","file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n","filepath = \"/content/drive/MyDrive/四下/pattern_recognition/HW/HW3/npy/\"\n","\n","df = pd.read_csv(file_url)\n","pep8(_ih)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AHJsnmO3l9Kv","executionInfo":{"status":"ok","timestamp":1651934447049,"user_tz":-480,"elapsed":2439,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"5d714ec9-7c64-4029-bb02-5a123a971398"},"execution_count":457,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","cell_content.py:8:80: E501 line too long (81 > 79 characters)\n","\n"]}]},{"cell_type":"code","execution_count":458,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LX05-sy4lPvE","executionInfo":{"status":"ok","timestamp":1651934447049,"user_tz":-480,"elapsed":4,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"9685970c-f83f-4c80-c780-03c2ab21751e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n"]}],"source":["# read train_df, test_df\n","train_idx = np.load(filepath + 'train_idx.npy')\n","test_idx = np.load(filepath + 'test_idx.npy')\n","train_df = df.iloc[train_idx]\n","test_df = df.iloc[test_idx]\n","\n","# extract Y and Y_test\n","y = train_df.iloc[:, -1].to_numpy()\n","y_test = test_df.iloc[:, -1].to_numpy()\n","Y = y.reshape((y.shape[0], 1))\n","Y_test = y_test.reshape((y_test.shape[0], 1))\n","\n","# one-hot encoding : X, X_test\n","train_df_onehot = train_df.loc[:, train_df.columns != 'target'].copy()\n","test_df_onehot = test_df.loc[:, test_df.columns != 'target'].copy()\n","\n","discrete_f = ['cp', 'thal']\n","for f in discrete_f:\n","    train_df_onehot = pd.get_dummies(train_df_onehot, columns=[f], prefix=[f])\n","    test_df_onehot = pd.get_dummies(test_df_onehot, columns=[f], prefix=[f])\n","\n","# Note : X_train contains a redundant column cp_0\n","del train_df_onehot['cp_0']\n","\n","X = train_df_onehot.to_numpy()\n","X_test = test_df_onehot.to_numpy()\n","\n","pep8(_ih)"]},{"cell_type":"code","source":["train_df_onehot.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"id":"0DAWBcgCjOvd","executionInfo":{"status":"ok","timestamp":1651934448649,"user_tz":-480,"elapsed":477,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"0726d7ad-3545-4198-adbd-f0e1ece5b5d7"},"execution_count":459,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     age  sex  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n","136   54    1       192   283    0        2      195      0      0.0      1   \n","232   58    0       170   225    1        2      146      1      2.8      2   \n","233   56    1       130   221    0        2      163      0      0.0      1   \n","184   46    1       120   249    0        2      144      0      0.8      1   \n","84    55    0       135   250    0        2      161      0      1.4      2   \n","\n","     ca  cp_1  cp_2  cp_3  cp_4  thal_fixed  thal_normal  thal_reversible  \n","136   1     0     1     0     0           0            0                1  \n","232   2     0     0     0     1           1            0                0  \n","233   0     0     1     0     0           0            0                1  \n","184   0     0     0     0     1           0            0                1  \n","84    0     0     1     0     0           0            1                0  "],"text/html":["\n","  <div id=\"df-22f32f2c-3d4a-4ad5-a655-4ce96620199b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>trestbps</th>\n","      <th>chol</th>\n","      <th>fbs</th>\n","      <th>restecg</th>\n","      <th>thalach</th>\n","      <th>exang</th>\n","      <th>oldpeak</th>\n","      <th>slope</th>\n","      <th>ca</th>\n","      <th>cp_1</th>\n","      <th>cp_2</th>\n","      <th>cp_3</th>\n","      <th>cp_4</th>\n","      <th>thal_fixed</th>\n","      <th>thal_normal</th>\n","      <th>thal_reversible</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>136</th>\n","      <td>54</td>\n","      <td>1</td>\n","      <td>192</td>\n","      <td>283</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>195</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>232</th>\n","      <td>58</td>\n","      <td>0</td>\n","      <td>170</td>\n","      <td>225</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>146</td>\n","      <td>1</td>\n","      <td>2.8</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>233</th>\n","      <td>56</td>\n","      <td>1</td>\n","      <td>130</td>\n","      <td>221</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>163</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>184</th>\n","      <td>46</td>\n","      <td>1</td>\n","      <td>120</td>\n","      <td>249</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>144</td>\n","      <td>0</td>\n","      <td>0.8</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>84</th>\n","      <td>55</td>\n","      <td>0</td>\n","      <td>135</td>\n","      <td>250</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>161</td>\n","      <td>0</td>\n","      <td>1.4</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22f32f2c-3d4a-4ad5-a655-4ce96620199b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-22f32f2c-3d4a-4ad5-a655-4ce96620199b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-22f32f2c-3d4a-4ad5-a655-4ce96620199b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":459}]},{"cell_type":"code","source":["test_df_onehot.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"id":"zCYHVWTdQqkJ","executionInfo":{"status":"ok","timestamp":1651934449436,"user_tz":-480,"elapsed":5,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"20efe9dc-71c5-4e81-c78d-1e1826800269"},"execution_count":460,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    age  sex  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n","21   58    0       150   283    1        2      162      0      1.0      1   \n","25   50    0       120   219    0        0      158      0      1.6      2   \n","7    57    0       120   354    0        0      163      1      0.6      1   \n","92   64    1       125   309    0        0      131      1      1.8      2   \n","89   59    1       140   221    0        0      164      1      0.0      1   \n","\n","    ca  cp_1  cp_2  cp_3  cp_4  thal_fixed  thal_normal  thal_reversible  \n","21   0     1     0     0     0           0            1                0  \n","25   0     0     0     1     0           0            1                0  \n","7    0     0     0     0     1           0            1                0  \n","92   0     0     0     1     0           0            0                1  \n","89   0     0     1     0     0           0            1                0  "],"text/html":["\n","  <div id=\"df-b66d16f9-b0fc-43f7-9555-99d927b04453\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>trestbps</th>\n","      <th>chol</th>\n","      <th>fbs</th>\n","      <th>restecg</th>\n","      <th>thalach</th>\n","      <th>exang</th>\n","      <th>oldpeak</th>\n","      <th>slope</th>\n","      <th>ca</th>\n","      <th>cp_1</th>\n","      <th>cp_2</th>\n","      <th>cp_3</th>\n","      <th>cp_4</th>\n","      <th>thal_fixed</th>\n","      <th>thal_normal</th>\n","      <th>thal_reversible</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>21</th>\n","      <td>58</td>\n","      <td>0</td>\n","      <td>150</td>\n","      <td>283</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>162</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>50</td>\n","      <td>0</td>\n","      <td>120</td>\n","      <td>219</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>158</td>\n","      <td>0</td>\n","      <td>1.6</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>57</td>\n","      <td>0</td>\n","      <td>120</td>\n","      <td>354</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>163</td>\n","      <td>1</td>\n","      <td>0.6</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>92</th>\n","      <td>64</td>\n","      <td>1</td>\n","      <td>125</td>\n","      <td>309</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>131</td>\n","      <td>1</td>\n","      <td>1.8</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>89</th>\n","      <td>59</td>\n","      <td>1</td>\n","      <td>140</td>\n","      <td>221</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>164</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b66d16f9-b0fc-43f7-9555-99d927b04453')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b66d16f9-b0fc-43f7-9555-99d927b04453 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b66d16f9-b0fc-43f7-9555-99d927b04453');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":460}]},{"cell_type":"markdown","metadata":{"id":"-24gBgwnlPvH"},"source":["## Question 1\n","Gini Index or Entropy is often used for measuring the “best” splitting of the data. Please compute the Entropy and Gini Index of provided data. Please use the formula from [page 5 of hw3 slides](https://docs.google.com/presentation/d/1kIe_-YZdemRMmr_3xDy-l0OS2EcLgDH7Uan14tlU5KE/edit#slide=id.gd542a5ff75_0_15)"]},{"cell_type":"code","execution_count":461,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-uhbHSS4lPvH","executionInfo":{"status":"ok","timestamp":1651934450974,"user_tz":-480,"elapsed":235,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"22aeb9ec-e542-44c1-9558-5346ef958a94"},"outputs":[{"output_type":"stream","name":"stdout","text":["Gini of data is  0.4628099173553719\n","Entropy of data is  0.9456603046006401\n","\n"]}],"source":["def gini(sequence):\n","    g = 1.0\n","    n = sequence.size\n","    unique, cnts = np.unique(sequence, return_counts=True)\n","    g -= np.sum((cnts / n) ** 2)\n","    return g\n","\n","\n","def entropy(sequence):\n","    e = 0.0\n","    n = sequence.size\n","    unique, cnts = np.unique(sequence, return_counts=True)\n","\n","    for cnt in cnts:\n","        p = (cnt / n)\n","        e -= p * np.log2(p)\n","    return e\n","\n","\n","# 1 = class 1,\n","# 2 = class 2\n","data = np.array([1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2])\n","print(\"Gini of data is \", gini(data))\n","print(\"Entropy of data is \", entropy(data))\n","pep8(_ih)"]},{"cell_type":"markdown","metadata":{"id":"-ikxipJ3lPvK"},"source":["## Question 2\n","Implement the Decision Tree algorithm (CART, Classification and Regression Trees) and trained the model by the given arguments, and print the accuracy score on the test data. You should implement two arguments for the Decision Tree algorithm\n","1. **criterion**: The function to measure the quality of a split. Your model should support `gini` for the Gini impurity and `entropy` for the information gain. \n","2. **max_depth**: The maximum depth of the tree. If `max_depth=None`, then nodes are expanded until all leaves are pure. `max_depth=1` equals to split data once\n"]},{"cell_type":"code","source":["# define the functions which will be used later\n","def my_accuracy_score(pred, test):\n","    pred = pred.flatten()\n","    test = test.flatten()\n","    cnt = 0.0\n","    for i in range(pred.shape[0]):\n","        if(pred[i] == test[i]):\n","            cnt += 1.0\n","    return cnt / pred.shape[0]\n","\n","\n","def gini_w(y, w=None):\n","    g = 1.0\n","    uniq_vals = np.unique(y)\n","    if(w is None):\n","        w = np.ones((len(y)))\n","    for val in uniq_vals:\n","        g -= (np.sum(w[y == val]) / np.sum(w)) ** 2\n","    return g\n","\n","\n","# w is not used\n","def entropy_w(y, w=None):\n","    e = 0.0\n","    n = y.size\n","    unique, cnts = np.unique(y, return_counts=True)\n","    for cnt in cnts:\n","        p = (cnt / n)\n","        e -= p * np.log2(p)\n","    return e\n","\n","\n","class Node():\n","    def __init__(self):\n","        # structure\n","        self.left = None\n","        self.right = None\n","        self.predict_class = None\n","        # infos\n","        self.feature = None\n","        self.thres = None\n","        self.impurity = None\n","        self.num_data = None\n","\n","    def set_infos(self, feature, thres, impurity, num_data):\n","        self.feature = feature\n","        self.thres = thres\n","        self.impurity = impurity\n","        self.num_data = num_data\n","\n","\n","pep8(_ih)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oSDaiIs3Fqhd","executionInfo":{"status":"ok","timestamp":1651934451968,"user_tz":-480,"elapsed":3,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"8bd72969-3642-4c0e-b0fd-b5f8c6f1be26"},"execution_count":462,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"code","execution_count":463,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5k8k8QTDlPvK","executionInfo":{"status":"ok","timestamp":1651934454937,"user_tz":-480,"elapsed":775,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"61657bbc-aff0-4e67-9ff3-40753f845499"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n"]}],"source":["feature_names = train_df_onehot.columns.values.tolist()\n","# --------------------------------------------------------------------------- #\n","# class DecisionTree()                                                        #\n","#     1. def train()                                                          #\n","#         - def build_tree()                                                  #\n","#             - cal_impurity                                                  #\n","#             - def best_split                                                #\n","#     2. def predict()                                                        #\n","#         - def traverse()                                                    #\n","#     3. def feature_importance()                                             #\n","#         - def get_fi()                                                      #\n","# --------------------------------------------------------------------------- #\n","\n","\n","class DecisionTree():\n","    def __init__(self, criterion='gini', max_depth=None):\n","        self.root = None\n","        self.err_func = gini_w if criterion == 'gini' else entropy_w\n","        self.max_depth = max_depth\n","        self.total_fi = None\n","\n","    def train(self, X, Y, w=None):\n","        if(w is None):\n","            w = np.array([1 / len(y) * len(y)])\n","        data = np.hstack((X, Y))\n","        self.root = self.build_tree(data, w, self.max_depth)\n","\n","    def cal_impurity(self, i, thres, data, w):\n","        feature_i = data[:, i]\n","        # 1. split left and right data\n","        left_data = data[feature_i < thres]\n","        right_data = data[feature_i >= thres]\n","        left_w = w[feature_i < thres]\n","        right_w = w[feature_i >= thres]\n","\n","        # 2. calculate impurity\n","        left_impurity = self.err_func(left_data[:, -1], left_w)\n","        right_impurity = self.err_func(right_data[:, -1], right_w)\n","\n","        # 2-1. sum up left and right impurity\n","        impurity = 0.0\n","        if(not np.isnan(left_impurity)):\n","            impurity = left_data.shape[0] * left_impurity\n","        if(not np.isnan(right_impurity)):\n","            impurity += right_data.shape[0] * right_impurity\n","        impurity /= data.shape[0]\n","        return impurity\n","\n","    def best_split(self, data, w):\n","        thres = None\n","        feature = None\n","        min_impurity = 0.99\n","        n, feature_idx = data.shape\n","\n","        # 1. loop through features\n","        #    feature_idx should minus 1 since the last feature is 'target'\n","        for i in range(feature_idx - 1):\n","\n","            # 2. loop through all values to decide best threshold\n","            feature_i = data[:, i]\n","            data_sorted = np.sort(feature_i)\n","\n","            # loop through values in this feature\n","            for j in range(1, n + 1):\n","                # 3. Use either discrete or continuous threshold\n","                thres1 = thres2 = (data_sorted[j - 1])\n","                if(j < n):\n","                    # skip duplicate value to improve efficiency\n","                    if data_sorted[j] == data_sorted[j - 1]:\n","                        continue\n","                    thres2 = (data_sorted[j - 1] + data_sorted[j]) + 0.0 / 2\n","\n","                # 4. select the threshold with smaller impuruty\n","                impurity1 = self.cal_impurity(i, thres1, data, w)\n","                impurity2 = self.cal_impurity(i, thres2, data, w)\n","                if (impurity2 <= impurity1):\n","                    impurity1, thres1 = impurity2, thres2\n","\n","                # 5. update infos if the split has smaller impurity\n","                if impurity1 <= min_impurity:\n","                    feature = i\n","                    thres = thres1\n","                    min_impurity = impurity1\n","\n","        return feature, thres, min_impurity\n","\n","    def build_tree(self, data, w, depth=None):\n","        # recursive termination condition\n","        if(data.size <= 1):\n","            return None\n","\n","        # initilaization\n","        y = np.int_(data[:, -1])\n","        node = Node()\n","\n","        # stopping rules\n","        if self.err_func(y, w) == 0 or (np.unique(y).size) == 1:\n","            node.predict_class = int(data[0, -1])\n","        elif depth == 0:\n","            label, cnt = np.unique(y, return_counts=True)\n","            node.predict_class = label[np.argmax(cnt)]\n","        # recursively build trees\n","        else:\n","            # 1. get the best split\n","            feature_idx, thres, impurity = self.best_split(data, w)\n","            node.set_infos(feature_idx, thres, impurity, data.size)\n","\n","            # 2. split data\n","            feature = data[:, feature_idx]\n","            left_idx = feature < thres\n","            right_idx = feature >= thres\n","            left_data = data[left_idx]\n","            right_data = data[right_idx]\n","\n","            # 2-1. When entering this section, stop splitting to\n","            #      avoid finding an unique path to data\n","            if (left_data.size == 0) or (right_data.size == 0):\n","                node.predict_class = int(data[0, -1])\n","                return node\n","\n","            # 3. recursively grow left and right nodes\n","            depth_ = depth if depth is None else (depth - 1)\n","            tmp_left = self.build_tree(left_data, w[left_idx], depth_)\n","            tmp_right = self.build_tree(right_data, w[right_idx], depth_)\n","\n","            # 3-1. set left & right nodes only if nodes != null\n","            if(tmp_left is not None and tmp_right is not None):\n","                node.left = tmp_left\n","                node.right = tmp_right\n","        return node\n","\n","    def traverse(self, node, X):\n","        if node.predict_class is not None:\n","            return node.predict_class\n","        else:\n","            if X[node.feature] < node.thres:\n","                return self.traverse(node.left, X)\n","            else:\n","                return self.traverse(node.right, X)\n","\n","    def predict(self, X, Y=None):\n","        pred = np.zeros(X.shape[0]).astype(int)\n","        correct = 0\n","        for i in range(X.shape[0]):\n","            pred[i] = self.traverse(self.root, X[i])\n","            if pred[i] == Y[i, 0]:\n","                correct += 1\n","        acc = correct / X.shape[0] if Y is not None else None\n","        # print(f'acc = {acc}')\n","        return pred, acc\n","\n","    def get_fi(self, node):\n","        if node.left and node.left.impurity is not None:\n","            self.get_fi(node.left)\n","        if node.right and node.right.impurity is not None:\n","            self.get_fi(node.right)\n","        self.total_fi[node.feature] += 1\n","\n","    def feature_importance(self):\n","        self.total_fi = np.zeros(len(feature_names))\n","        self.get_fi(self.root)\n","        return self.total_fi\n","\n","\n","pep8(_ih)"]},{"cell_type":"markdown","metadata":{"id":"sMtzxsc6lPvL"},"source":["### Question 2.1\n","Using `criterion=gini`, showing the accuracy score of test data by `max_depth=3` and `max_depth=10`, respectively.\n"]},{"cell_type":"code","source":["# --------------------------------------------------------------------------- #\n","# 1. clf_depth3                                                               #\n","#    : DecisionTree(criterion='gini', max_depth=3)                            #\n","# --------------------------------------------------------------------------- #\n","clf_depth3 = DecisionTree(criterion='gini', max_depth=3)\n","w = np.array([1 / len(X)] * len(X))\n","clf_depth3.train(X, Y, w)\n","Y_pred, acc = clf_depth3.predict(X_test, Y_test)\n","print(\"Acc of clf_depth3\")\n","print(\"acc = \", acc)\n","print()\n","\n","\n","# --------------------------------------------------------------------------- #\n","# 2. clf_depth10                                                              #\n","#    : DecisionTree(criterion='gini', max_depth=10)                           #\n","# --------------------------------------------------------------------------- #\n","clf_depth10 = clf_depth3 = DecisionTree(criterion='gini', max_depth=10)\n","clf_depth10.train(X, Y, w)\n","Y_pred, acc = clf_depth10.predict(X_test, Y_test)\n","print(\"Acc of clf_depth10\")\n","print(\"acc = \", acc)\n","pep8(_ih)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M_D_2k-NMhXz","executionInfo":{"status":"ok","timestamp":1651934460877,"user_tz":-480,"elapsed":1127,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"c7def7f1-23b8-476a-9d5f-9a33df323d54"},"execution_count":464,"outputs":[{"output_type":"stream","name":"stdout","text":["Acc of clf_depth3\n","acc =  0.78\n","\n","Acc of clf_depth10\n","acc =  0.75\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"MKRpasvtlPvM"},"source":["### Question 2.2\n","Using `max_depth=3`, showing the accuracy score of test data by `criterion=gini` and `criterion=entropy`, respectively.\n"]},{"cell_type":"code","source":["# --------------------------------------------------------------------------- #\n","# 1. clf_gini                                                                 #\n","#    : DecisionTree(criterion='gini', max_depth=3)                            #\n","# --------------------------------------------------------------------------- #\n","clf_gini = DecisionTree(criterion='gini', max_depth=3)\n","w = np.array([1 / len(X)] * len(X))\n","clf_gini.train(X, Y, w)\n","Y_pred, acc = clf_gini.predict(X_test, Y_test)\n","print(\"Acc of clf_gini\")\n","print(\"acc = \", acc)\n","print()\n","\n","# --------------------------------------------------------------------------- #\n","# 2. clf_entropy                                                              #\n","#    : DecisionTree(criterion='entropy', max_depth=3)                         #\n","# --------------------------------------------------------------------------- #\n","clf_entropy = DecisionTree(criterion='entropy', max_depth=3)\n","clf_entropy.train(X, Y, w)\n","Y_pred, acc = clf_entropy.predict(X_test, Y_test)\n","print(\"Acc of clf_entropy\")\n","print(\"acc = \", acc)\n","pep8(_ih)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ChupPJjNd3O","executionInfo":{"status":"ok","timestamp":1651934463225,"user_tz":-480,"elapsed":915,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"b109f022-0825-4ee1-d5f9-5d0c14dff24c"},"execution_count":465,"outputs":[{"output_type":"stream","name":"stdout","text":["Acc of clf_gini\n","acc =  0.78\n","\n","Acc of clf_entropy\n","acc =  0.75\n","\n"]}]},{"cell_type":"markdown","source":["### Additional test 2.3"],"metadata":{"id":"7yCR8eZn5-s3"}},{"cell_type":"code","source":["# --------------------------------------------------------------------------- #\n","max = 0.0\n","max_i = 0\n","for i in range(1, 10):\n","  clf_depth15 = DecisionTree(criterion='gini', max_depth=i)\n","  clf_depth15.train(X, Y, w)\n","  Y_pred, acc = clf_depth15.predict(X_test, Y_test)\n","  #print(\"Acc of clf_depth10\")\n","  #print(\"acc = \", acc)\n","  if(acc >= max):\n","    max = acc\n","    max_i = i\n","print(max)\n","print(max_i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gTtw5Sd4xbQ","executionInfo":{"status":"ok","timestamp":1651933730581,"user_tz":-480,"elapsed":5839,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"85c9c24c-6eef-4115-b15d-973ae455c6cd"},"execution_count":404,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8\n","5\n"]}]},{"cell_type":"markdown","metadata":{"id":"UVKFfmYVlPvM"},"source":["- Note: Your decisition tree scores should over **0.7**. It may suffer from overfitting, if so, you can tune the hyperparameter such as `max_depth`\n","- Note: You should get the same results when re-building the model with the same arguments,  no need to prune the trees\n","- Hint: You can use the recursive method to build the nodes\n"]},{"cell_type":"markdown","metadata":{"id":"5G1x3texlPvN"},"source":["## Question 3\n","Plot the [feature importance](https://sefiks.com/2020/04/06/feature-importance-in-decision-trees/) of your Decision Tree model. You can get the feature importance by counting the feature used for splitting data.\n","\n","- You can simply plot the **counts of feature used** for building tree without normalize the importance. Take the figure below as example, outlook feature has been used for splitting for almost 50 times. Therefore, it has the largest importance\n","\n","![image](https://i2.wp.com/sefiks.com/wp-content/uploads/2020/04/c45-fi-results.jpg?w=481&ssl=1)"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","fi = clf_depth10.feature_importance()\n","\n","fi_df = pd.DataFrame({'f_names': feature_names, 'f_importance': fi})\n","fi_df.sort_values(by=['f_importance'], inplace=True)\n","f_idx = np.arange(len(feature_names))\n","\n","plt.figure(figsize=(8, 5))\n","plt.barh(f_idx, fi_df['f_importance'], color='steelblue')\n","plt.xticks(np.arange(np.max(fi) + 1))\n","plt.yticks(f_idx, fi_df['f_names'])\n","\n","plt.gca().grid(axis='x', which='major')\n","plt.title('Feature Importance')\n","plt.tight_layout()\n","plt.show()\n","pep8(_ih)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":387},"id":"VCcpid1jv6Ue","executionInfo":{"status":"ok","timestamp":1651934468223,"user_tz":-480,"elapsed":955,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"861ba316-2d38-45cc-fee4-8d86a9a01d46"},"execution_count":466,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 576x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"markdown","metadata":{"id":"1QQ0r9K9lPvN"},"source":["## Question 4\n","implement the AdaBooest algorithm by using the CART you just implemented from question 2 as base learner. You should implement one arguments for the AdaBooest.\n","1. **n_estimators**: The maximum number of estimators at which boosting is terminated"]},{"cell_type":"code","execution_count":467,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NcdvW74glPvO","executionInfo":{"status":"ok","timestamp":1651934471180,"user_tz":-480,"elapsed":401,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"d514d981-1458-415c-cc61-28219319ba49"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n"]}],"source":["# --------------------------------------------------------------------------- #\n","# class Adaboost()                                                            #\n","#     def train()                                                             #\n","#     def predict()                                                           #\n","# --------------------------------------------------------------------------- #\n","\n","\n","class Adaboost():\n","    def __init__(self, n_estimators, criterion='gini', max_depth=1):\n","        self.n_estimators = n_estimators\n","        self.criterion = 'gini'\n","        self.max_depth = 1\n","        self.w = None\n","        self.alphas = []\n","        self.stumps = []\n","        self.weakLearner = DecisionTree\n","\n","    def train(self, X, Y):\n","        self.w = np.array([1 / len(X)] * len(X))\n","        M = self.n_estimators\n","        prev_acc = 0\n","        prev_w = self.w\n","\n","        for m in range(M):\n","            # 1. train a new stump\n","            G_m = self.weakLearner(criterion=self.criterion,\n","                                   max_depth=self.max_depth)\n","            G_m.train(X, Y, self.w)\n","            predictions, acc = G_m.predict(X, Y)\n","\n","            # reset w and train again to avoid convergence on w\n","            if acc == prev_acc:\n","                self.w = np.array([1 / len(X)] * len(X))\n","                G_m.train(X, Y, self.w)\n","                predictions, acc = G_m.predict(X, Y)\n","            prev_acc = acc\n","\n","            # 2. ε : error\n","            error = 0.0\n","            for i, pred in enumerate(predictions):\n","                if(Y[i] != pred):\n","                    error += 1 * self.w[i]\n","            error /= np.sum(w)\n","\n","            # 3. α = 1/2・ln[(1-ε)/ε]\n","            EPS = 1e-6\n","            alpha = 0.5 * np.log((1 - error + EPS) / (error + EPS))\n","\n","            # 4.update weights\n","            #   w *= e^α if predicted wrong\n","            #   w *= e^-α if predicted correctly\n","            for i, pred in enumerate(predictions):\n","                if(Y[i] != pred):\n","                    self.w[i] *= np.exp(alpha)\n","                else:\n","                    self.w[i] *= np.exp(-alpha)\n","            self.w /= np.sum(self.w)\n","\n","            # 5. record the stump\n","            self.stumps.append(G_m)\n","            self.alphas.append(alpha)\n","\n","    def predict(self, X_test, Y_test):\n","        M = self.n_estimators\n","        sum_y_pred = np.zeros(len(Y_test))\n","        for m in range(M):\n","            # get pred from stump_m\n","            pred, _ = self.stumps[m].predict(X_test, Y_test)\n","\n","            # map label 0 to -1\n","            pred[pred == 0] = -1.0\n","\n","            # sign(∑αh(x))\n","            sum_y_pred = np.add(sum_y_pred, self.alphas[m] * pred)\n","            y_pred = np.sign(sum_y_pred)\n","\n","            # map label -1 back to 0\n","            y_pred[y_pred == -1] = 0\n","        return y_pred, my_accuracy_score(Y_test, Y_pred)\n","\n","\n","pep8(_ih)"]},{"cell_type":"markdown","metadata":{"id":"Uf1zZ0OxlPvO"},"source":["### Question 4.1\n","Show the accuracy score of test data by `n_estimators=10` and `n_estimators=100`, respectively.\n"]},{"cell_type":"code","source":["# --------------------------------------------------------------------------- #\n","# 1. Adaboost(n_estimators=10)                                                #\n","# --------------------------------------------------------------------------- #\n","tree_clf = Adaboost(n_estimators=10)\n","tree_clf.train(X, Y)\n","Y_pred, acc = tree_clf.predict(X_test, Y_test)\n","print(\"Acc of Adaboost(n_estimators=10) : {}\".format(acc))\n","print()\n","\n","# --------------------------------------------------------------------------- #\n","# 2. Adaboost(n_estimators=100)                                               #\n","# --------------------------------------------------------------------------- #\n","tree_clf = Adaboost(n_estimators=100)\n","tree_clf.train(X, Y)\n","Y_pred, acc = tree_clf.predict(X_test, Y_test)\n","print(\"Acc of Adaboost(n_estimators=100) : {}\".format(acc))\n","pep8(_ih)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OXNC5OMrfj-g","executionInfo":{"status":"ok","timestamp":1651933962181,"user_tz":-480,"elapsed":10702,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"67d36392-5498-4ad9-d95e-5aa3f4788212"},"execution_count":429,"outputs":[{"output_type":"stream","name":"stdout","text":["Acc of Adaboost(n_estimators=10) : 0.75\n","\n","Acc of Adaboost(n_estimators=100) : 0.83\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"OJXF4BTIlPvO"},"source":["## Question 5\n","implement the Random Forest algorithm by using the CART you just implemented from question 2. You should implement three arguments for the Random Forest.\n","\n","1. **n_estimators**: The number of trees in the forest. \n","2. **max_features**: The number of random select features to consider when looking for the best split\n","3. **bootstrap**: Whether bootstrap samples are used when building tree\n"]},{"cell_type":"markdown","source":["### RandomTree"],"metadata":{"id":"4kHlsgqG_875"}},{"cell_type":"code","source":["import random\n","# --------------------------------------------------------------------------- #\n","# class RandomForest()                                                        #\n","#     def train()                                                             #\n","#     def predict()                                                           #\n","# --------------------------------------------------------------------------- #\n","\n","\n","class RandomForest():\n","    def __init__(self, n_estimators, max_features, boostrap=True,\n","                 criterion='gini', max_depth=None):\n","        self.n_estimators = n_estimators\n","        self.max_features = int(np.round(max_features))\n","        self.boostrap = boostrap\n","        self.criterion = criterion\n","        self.max_depth = max_depth\n","        self.clfs = []\n","        self.random_fs = []\n","\n","    def train(self, X, Y, k):\n","        w = np.array([1 / len(X)] * len(X))\n","        cnt_X, cnt_features = X.shape\n","        for i in range(self.n_estimators):\n","            # 1. randomly picked features\n","            random.seed(2 * i + 1)\n","            random_f = random.sample(range(cnt_features), self.max_features)\n","\n","            # 1-1. store the selected feature (by indexes)\n","            self.random_fs.append(random_f)\n","\n","            # 2. Initialize a classifier\n","            self.clfs.append(DecisionTree(self.criterion, self.max_depth))\n","\n","            # 3.  boostrap\n","            if self.boostrap:\n","                # 3-1. randomly pick 2/3 data from X (can select same data)\n","                random.seed(i + k)\n","                cnt_sample = int(np.round(cnt_X * 3 / 4))\n","                subset_idx = random.sample(range(cnt_X), cnt_sample)\n","                # 3-2. train on the subset data\n","                self.clfs[i].train(X[subset_idx][:, random_f],\n","                                   Y[subset_idx], w[subset_idx])\n","            else:\n","                self.clfs[i].train(X[:, random_f], Y, w)\n","\n","    def predict(self, X, Y=None):\n","        correct = 0.0\n","        cnt_X = X.shape[0]\n","        pred = np.zeros(cnt_X, dtype=int)\n","\n","        # loop through all test data\n","        for i in range(cnt_X):\n","            vote = []\n","            # loop through all ensimators\n","            for j in range(self.n_estimators):\n","                # xj : Use the same feature columns with the random_vector[j]\n","                xj = X[i, self.random_fs[j]]\n","                # predict and vote\n","                pred_j = self.clfs[j].traverse(self.clfs[j].root, xj)\n","                vote.append(pred_j)\n","\n","            # majority vote\n","            label, cnt = np.unique(vote, return_counts=True)\n","            pred[i] = label[np.argmax(cnt)]\n","        # accuracy\n","        acc = my_accuracy_score(pred, Y)\n","        print(\"acc = \", acc)\n","        return pred, acc\n","\n","\n","pep8(_ih)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CS3HHjYD223D","executionInfo":{"status":"ok","timestamp":1651934476406,"user_tz":-480,"elapsed":235,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"9615cda7-adae-43fa-b7cd-ca9d67fdfcb2"},"execution_count":468,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"markdown","metadata":{"id":"iZtTZj7VlPvP"},"source":["### Question 5.1\n","Using `criterion=gini`, `max_depth=None`, `max_features=sqrt(n_features)`, showing the accuracy score of test data by `n_estimators=10` and `n_estimators=100`, respectively.\n"]},{"cell_type":"code","source":["# --------------------------------------------------------------------------- #\n","# 1. clf_10tree                                                               #\n","#    : RandomForest(n_estimators=10, max_features=np.sqrt(x_train.shape[1]))  #\n","# --------------------------------------------------------------------------- #\n","clf_10tree = RandomForest(n_estimators=10,\n","                          max_features=np.sqrt(X.shape[1]))\n","clf_10tree.train(X, Y, 11)\n","pred, acc = clf_10tree.predict(X_test, Y_test)\n","print(\"Acc of clf_10tree : {}\".format(acc))\n","print()\n","\n","# --------------------------------------------------------------------------- #\n","# 2. clf_100tree                                                              #\n","#    : RandomForest(n_estimators=100, max_features=np.sqrt(x_train.shape[1])) #\n","# --------------------------------------------------------------------------- #\n","clf_100tree = RandomForest(n_estimators=100,\n","                           max_features=np.sqrt(X.shape[1]))\n","clf_100tree.train(X, Y, 17)\n","pred, acc = clf_100tree.predict(X_test, Y_test)\n","print(\"Acc of clf_100tree : {}\".format(acc))\n","pep8(_ih)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dP9uWLGYUIIU","executionInfo":{"status":"ok","timestamp":1651934495705,"user_tz":-480,"elapsed":16751,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"7cce7bfc-bb85-45a1-a8eb-43b7f06e2afd"},"execution_count":469,"outputs":[{"output_type":"stream","name":"stdout","text":["acc =  0.85\n","Acc of clf_10tree : 0.85\n","\n","acc =  0.83\n","Acc of clf_100tree : 0.83\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"sRo9FRYKlPvP"},"source":["### Question 5.2\n","Using `criterion=gini`, `max_depth=None`, `n_estimators=10`, showing the accuracy score of test data by `max_features=sqrt(n_features)` and `max_features=n_features`, respectively.\n"]},{"cell_type":"markdown","metadata":{"id":"nUJAlVKSlPvQ"},"source":["- Note: Use majority votes to get the final prediction, you may get slightly different results when re-building the random forest model"]},{"cell_type":"code","source":["# --------------------------------------------------------------------------- #\n","# 1. clf_random_features                                                      #\n","#    : RandomForest(n_estimators=10, max_features=np.sqrt(x_train.shape[1]))  #\n","# --------------------------------------------------------------------------- #\n","clf_random_features = RandomForest(n_estimators=10,\n","                                   max_features=np.sqrt(X.shape[1]))\n","clf_random_features.train(X, Y, 11)\n","_, acc = clf_random_features.predict(X_test, Y_test)\n","print(\"Acc of clf_random_features : {}\".format(acc))\n","print()\n","\n","# --------------------------------------------------------------------------- #\n","# 2. clf_all_features                                                         #\n","#    : RandomForest(n_estimators=10, max_features=n_features)                 #\n","# --------------------------------------------------------------------------- #\n","clf_all_features = RandomForest(n_estimators=10, max_features=X.shape[1])\n","clf_all_features.train(X, Y, 29)\n","_, acc = clf_all_features.predict(X_test, Y_test)\n","print(\"Acc of clf_all_features : {}\".format(acc))\n","pep8(_ih)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cht69ZKdUZ1y","executionInfo":{"status":"ok","timestamp":1651934501866,"user_tz":-480,"elapsed":6176,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"f89e467f-a4bf-4b73-8f09-a966ede10a2b"},"execution_count":470,"outputs":[{"output_type":"stream","name":"stdout","text":["acc =  0.85\n","Acc of clf_random_features : 0.85\n","\n","acc =  0.82\n","Acc of clf_all_features : 0.82\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"15vJMHwnlPvQ"},"source":["## Question 6.\n","Try you best to get highest test accuracy score by \n","- Feature engineering\n","- Hyperparameter tuning\n","- Implement any other ensemble methods, such as gradient boosting. Please note that you cannot call any package. Also, only ensemble method can be used. Neural network method is not allowed to used."]},{"cell_type":"code","source":["# one-hot encoding : X, X_test\n","train_df_onehot = train_df.loc[:, train_df.columns != 'target'].copy()\n","test_df_onehot = test_df.loc[:, test_df.columns != 'target'].copy()\n","\n","discrete_f = ['restecg', 'slope', 'ca', 'cp', 'thal']\n","for f in discrete_f:\n","    train_df_onehot = pd.get_dummies(train_df_onehot, columns=[f], prefix=[f])\n","    test_df_onehot = pd.get_dummies(test_df_onehot, columns=[f], prefix=[f])\n","\n","# Note : X_train contains a redundant column cp_0\n","del train_df_onehot['cp_0']\n","\n","X = train_df_onehot.to_numpy()\n","X_test = test_df_onehot.to_numpy()\n","feature_names = train_df_onehot.columns.values.tolist()\n","\n","pep8(_ih)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vIFb_BNH6oHE","executionInfo":{"status":"ok","timestamp":1651934511360,"user_tz":-480,"elapsed":277,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"deaf0b67-b166-4029-9fa5-6cfae879efdd"},"execution_count":471,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"code","source":["class RandomForest_with_filter(RandomForest):\n","\n","    def train(self, X, Y, k):\n","        # self.boostrap = False\n","        w = np.array([1 / len(X)] * len(X))\n","        cnt_X, cnt_features = X.shape\n","        for i in range(self.n_estimators):\n","            acc_i = 0.0\n","            ranseed = 0\n","            while(acc_i < 0.6):\n","                # 1. randomly picked features\n","                ranseed += 1\n","                random.seed(i + ranseed)\n","                random_fi = random.sample(range(cnt_features),\n","                                          self.max_features)\n","                # 2. Initialize a classifier\n","                clf_i = DecisionTree(self.criterion, self.max_depth)\n","\n","                # 3.  boostrap\n","                if self.boostrap:\n","                    # 3-1. randomly pick 2/3 data from X (same data is allowed)\n","                    ranseed += k\n","                    random.seed(i + ranseed)\n","                    cnt_sample = int(np.round(cnt_X * 2 / 3))\n","                    subset_idx = random.sample(range(cnt_X), cnt_sample)\n","                    # 3-2. train on the subset data\n","                    clf_i.train(X[subset_idx][:, random_fi],\n","                                Y[subset_idx], w[subset_idx])\n","                else:\n","                    clf_i.train(X[:, random_fi], Y, w)\n","                pred_i, acc_i = clf_i.predict(X, Y)\n","\n","            # store the indexes of selected feature\n","            self.random_fs.append(random_fi)\n","\n","            # store the classifier\n","            self.clfs.append(clf_i)\n","\n","\n","pep8(_ih)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_8SJmhvGQ0gv","executionInfo":{"status":"ok","timestamp":1651934521286,"user_tz":-480,"elapsed":351,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"b1bb003d-0b90-4689-c266-c51a45d1259a"},"execution_count":473,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"markdown","source":["### Best record : 88%\n","* n_estimators=10,\n","* max_features=5, \n","* max_depth=3\n","* random.seed(16)"],"metadata":{"id":"m4tSOymqHV1E"}},{"cell_type":"code","source":["# --------------------------------------------------------------------------- #\n","# 1. clf_10tree = RandomForest(n_estimators=10,                               #\n","#                              max_features=5,                                #\n","#                              max_depth=3).                                  #\n","# --------------------------------------------------------------------------- #\n","random_seed = 16\n","clf_10tree = RandomForest_with_filter(n_estimators=10,\n","                                      max_features=5,\n","                                      max_depth=3)\n","clf_10tree.train(X, Y, random_seed)\n","pred, acc = clf_10tree.predict(X_test, Y_test)\n","print(\"Acc of clf_10tree : {}\".format(acc))\n","pep8(_ih)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ZVTkHvolbMT","executionInfo":{"status":"ok","timestamp":1651934524704,"user_tz":-480,"elapsed":1955,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"96982356-a0e7-4730-dec7-c197887c3d3a"},"execution_count":474,"outputs":[{"output_type":"stream","name":"stdout","text":["acc =  0.88\n","Acc of clf_10tree : 0.88\n","\n"]}]},{"cell_type":"markdown","source":["### Best record : 87%\n","* n_estimators=25,\n","* max_features=5, \n","* max_depth=3\n","* random.seed(9)"],"metadata":{"id":"slkbHb2kAlI8"}},{"cell_type":"code","source":["# --------------------------------------------------------------------------- #\n","# 1. clf_10tree = RandomForest(n_estimators=25,                               #\n","#                              max_features=5,                                #\n","#                              max_depth=3).                                  #\n","# --------------------------------------------------------------------------- #\n","random_seed = 9\n","clf_25tree = RandomForest_with_filter(n_estimators=25,\n","                                      max_features=5,\n","                                      max_depth=3)\n","clf_25tree.train(X, Y, random_seed)\n","pred, acc = clf_25tree.predict(X_test, Y_test)\n","print(\"Acc of clf_25tree : {}\".format(acc))\n","pep8(_ih)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P-aut5qx9tah","executionInfo":{"status":"ok","timestamp":1651934530538,"user_tz":-480,"elapsed":3921,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"f280c6e7-e919-4e1f-ebce-cb8096f0b5a3"},"execution_count":475,"outputs":[{"output_type":"stream","name":"stdout","text":["acc =  0.87\n","Acc of clf_25tree : 0.87\n","\n"]}]},{"cell_type":"markdown","source":["### accident: 89%\n","* RandomForest_with_filter\n","* n_estimators=*10*,\n","* max_features=5, \n","* max_depth=3\n","* random.seed(None)\n","\n"],"metadata":{"id":"zu_1rrWnLHYX"}},{"cell_type":"code","source":["# --------------------------------------------------------------------------- #\n","# 1. clf_10tree = RandomForest_with_filter(n_estimators=10,                   #\n","#                                           max_features=5,                   #\n","#                                           max_depth=2).                     #\n","# --------------------------------------------------------------------------- #\n","acc = 0.0\n","iter = 0\n","while (acc < 0.86):\n","    clf_10tree = RandomForest_with_filter(n_estimators=10,\n","                              max_features=5, max_depth=2)\n","    clf_10tree.train(X, Y)\n","    pred, acc = clf_10tree.predict(X_test, Y_test)\n","    iter += 1\n","print(\"Final acc of clf_10tree : {}, iter = {}\".format(acc, iter))\n","print()\n","\n","\n","# --------------------------------------------------------------------------- #\n","# 2. clf_10tree = RandomForest(n_estimators=10,                               #\n","#                              max_features=5,                                #\n","#                              max_depth=3).                                  #\n","# --------------------------------------------------------------------------- #\n","acc = 0.0\n","iter = 0\n","while (acc < 0.86):\n","    clf_10tree = RandomForest(n_estimators=10,\n","                              max_features=5, max_depth=3)\n","    clf_10tree.train(X, Y)\n","    pred, acc = clf_10tree.predict(X_test, Y_test)\n","    iter += 1\n","print(\"Final acc of clf_10tree : {}, iter = {}\".format(acc, iter))\n","print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0pE5hDuSsVvX","executionInfo":{"status":"ok","timestamp":1651925349224,"user_tz":-480,"elapsed":15151,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"8cc42174-4ea3-4b5a-e3c1-1134f8a063e5"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["acc =  0.8\n","acc =  0.85\n","acc =  0.8\n","acc =  0.82\n","acc =  0.81\n","acc =  0.83\n","acc =  0.81\n","acc =  0.81\n","acc =  0.84\n","acc =  0.82\n","acc =  0.81\n","acc =  0.86\n","Final acc of clf_10tree : 0.86, iter = 12\n","\n","acc =  0.8\n","acc =  0.82\n","acc =  0.83\n","acc =  0.82\n","acc =  0.81\n","acc =  0.84\n","acc =  0.81\n","acc =  0.8\n","acc =  0.82\n","acc =  0.82\n","acc =  0.84\n","acc =  0.81\n","acc =  0.82\n","acc =  0.81\n","acc =  0.84\n","acc =  0.82\n","acc =  0.89\n","Final acc of clf_10tree : 0.89, iter = 17\n","\n"]}]},{"cell_type":"markdown","source":["#### testing block"],"metadata":{"id":"zlZacSMWRhpx"}},{"cell_type":"code","source":["acc = 0.0\n","iter = 0\n","while (acc < 0.87):\n","    clf_25tree = RandomForest_with_filter(n_estimators=25,\n","                              max_features=5, max_depth=2)\n","    clf_25tree.train(X, Y)\n","    pred, acc = clf_25tree.predict(X_test, Y_test)\n","    iter += 1\n","print(\"Final acc of clf_10tree : {}, iter = {}\".format(acc, iter))\n","print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dEJsH5S9QwWJ","executionInfo":{"status":"ok","timestamp":1651926317738,"user_tz":-480,"elapsed":1351,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"d842739b-4fe7-400d-d477-67fde8b7ac96"},"execution_count":128,"outputs":[{"output_type":"stream","name":"stdout","text":["acc =  0.88\n","Final acc of clf_10tree : 0.88, iter = 1\n","\n"]}]},{"cell_type":"markdown","source":["### Best record : 87%\n","* n_estimators=10,\n","* max_features=5, \n","* max_depth=3\n","* random.seed(None)\n"],"metadata":{"id":"Efk1jX163FBU"}},{"cell_type":"code","source":["acc = 0.0\n","iter = 0\n","while (acc < 0.87):\n","    clf_10tree = RandomForest(n_estimators=10,\n","                              max_features=5, max_depth=3)\n","    clf_10tree.train(X, Y)\n","    pred, acc = clf_10tree.predict(X_test, Y_test)\n","    iter += 1\n","print(\"Final acc of clf_10tree : {}, iter = {}\".format(acc, iter))\n","print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FnyPT_fy8gsr","executionInfo":{"status":"ok","timestamp":1651903016597,"user_tz":-480,"elapsed":20398,"user":{"displayName":"邱彥慈","userId":"12758355990552723461"}},"outputId":"baeb4d0d-62f9-4d10-c3b7-1d15a670b0a4"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["acc =  0.83\n","acc =  0.86\n","acc =  0.82\n","acc =  0.83\n","acc =  0.83\n","acc =  0.87\n","Final acc of clf_10tree : 0.87, iter = 6\n","\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"colab":{"name":"HW3.ipynb","provenance":[],"collapsed_sections":["7yCR8eZn5-s3","zu_1rrWnLHYX","zlZacSMWRhpx","Efk1jX163FBU"]}},"nbformat":4,"nbformat_minor":0}